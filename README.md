# ğŸš STM Real-Time Transit Data Platform

A production-grade data engineering platform that ingests, transforms, and models Montreal's public transit (STM) data in real-time, combining vehicle positions, GTFS schedules, and weather data into analytics-ready tables.

Built on **Databricks** with **Delta Lake** and **dbt**, following modern data engineering best practices: medallion architecture, incremental processing, automated data quality, and full orchestration.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     DATA SOURCES    â”‚     â”‚    BRONZE    â”‚    â”‚   SILVER & GOLD (dbt)        â”‚
â”‚                     â”‚     â”‚  (PySpark)   â”‚    â”‚                              â”‚
â”‚  STM GTFS-RT API â”€â”€â”€â”¼â”€â”€â”€â”€â–ºâ”‚ vehicle_pos  â”‚    â”‚  10 Staging Views            â”‚
â”‚  (Protobuf, 5 min   â”‚     â”‚              â”œâ”€â”€â”€â–ºâ”‚  6 Silver Tables (dims/facts)â”‚
â”‚                     â”‚     â”‚              â”‚    â”‚  3 Gold Tables (analytics)   â”‚
â”‚  STM Static GTF â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–ºâ”‚ gtfs_*       â”‚    â”‚                              â”‚
â”‚  (Monthly refrsh)   â”‚     â”‚              â”‚    â”‚  57 Automated Data Tests     â”‚
â”‚                     â”‚     â”‚              â”‚    â”‚                              â”‚
â”‚  Open-Meteo PI â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–ºâ”‚ weather      â”‚    â”‚                              â”‚
â”‚  (Daily bacfill)    â”‚     â”‚              â”‚    â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

| Layer | Technology |
|-------|-----------|
| **Cloud Platform** | Databricks (Unity Catalog) |
| **Storage** | Delta Lake (Lakehouse) |
| **Ingestion** | PySpark, Protobuf, REST APIs |
| **Transformation** | dbt-core + dbt-databricks |
| **Orchestration** | Databricks Workflows |
| **Data Quality** | dbt tests (57 assertions) |
| **Version Control** | Git + GitHub |
| **BI Layer** | Power BI (Gold tables) |

## Data Sources

- **STM GTFS-RT** â€” Real-time vehicle positions via Protobuf API (every 5 minutes, ~160K records/day)
- **STM Static GTFS** â€” Routes, stops, trips, schedules, shapes, calendar (monthly refresh)
- **Open-Meteo** â€” Hourly weather observations for Montreal (temperature, precipitation, wind, conditions)

## Medallion Architecture

### Bronze (PySpark Notebooks)
Raw data parsed and stored as Delta tables with full metadata tracking.

| Table | Source | Records |
|-------|--------|---------|
| `vehicle_positions` | GTFS-RT Protobuf | ~160K/day |
| `gtfs_routes` | Static GTFS | 250+ routes |
| `gtfs_stops` | Static GTFS | 8,900+ stops |
| `gtfs_trips` | Static GTFS | 78,000+ trips |
| `gtfs_stop_times` | Static GTFS | 2.6M+ stop times |
| `weather` | Open-Meteo API | 24 records/day |

### Silver (dbt â€” 16 models)

**Staging Views (10)** â€” Type casting, cleaning, business logic:
`stg_vehicle_positions` Â· `stg_weather` Â· `stg_routes` Â· `stg_stops` Â· `stg_trips` Â· `stg_stop_times` Â· `stg_calendar` Â· `stg_calendar_dates` Â· `stg_shapes` Â· `stg_agency`

**Dimension & Fact Tables (6)**:
- `dim_routes` â€” Route dimension with type descriptions and surrogate keys
- `dim_stops` â€” Stop dimension with GPS coordinates
- `dim_calendar` â€” Service calendar with pattern classification (Weekday/Weekend/Daily)
- `fact_vehicle_positions` â€” Deduplicated positions with dimension keys
- `fact_trips` â€” Trips enriched with route context and direction labels
- `fact_stop_times` â€” Stop times denormalized with stop/trip/route info

### Gold (dbt â€” 3 models)

| Model | Purpose |
|-------|---------|
| `fct_daily_performance` | Daily route metrics + weather context (temperature, precipitation, dominant weather) |
| `fct_route_analytics` | Route-level statistics: trip counts, stop coverage, outbound/inbound balance |
| `obt_positions_wide` | One Big Table â€” every position with route + hourly weather joined (BI-ready) |

## Data Quality

57 automated dbt tests covering all layers:

- **not_null** â€” No missing values in critical columns
- **unique** â€” No duplicate primary keys
- **accepted_values** â€” Validated enums (weather categories, service patterns, exception types)
- **referential integrity** â€” Foreign key relationships validated

## Pipeline Orchestration

| Job | Schedule | Tasks |
|-----|----------|-------|
| `STM_Vehicle_Positions_Pipeline` | Every 5 minutes | Ingest â†’ Bronze |
| `STM_Weather` | Daily 7:00 AM | Ingest â†’ Bronze â†’ dbt build (19 models + 57 tests) |
| `STM_GTFS_Static_Pipeline` | 1st of month | Ingest â†’ Bronze |
| `STM_Weekly_Maintenance` | Sunday 3:00 AM | OPTIMIZE Delta tables |

## Project Structure

```
stm-dbt/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/          # 10 staging views + source/model configs
â”‚   â”‚   â”œâ”€â”€ _stg__sources.yml
â”‚   â”‚   â”œâ”€â”€ _stg__models.yml
â”‚   â”‚   â”œâ”€â”€ stg_vehicle_positions.sql
â”‚   â”‚   â”œâ”€â”€ stg_weather.sql
â”‚   â”‚   â”œâ”€â”€ stg_routes.sql
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ silver/           # 6 dimension & fact tables
â”‚   â”‚   â”œâ”€â”€ dim_routes.sql
â”‚   â”‚   â”œâ”€â”€ dim_stops.sql
â”‚   â”‚   â”œâ”€â”€ dim_calendar.sql
â”‚   â”‚   â”œâ”€â”€ fact_vehicle_positions.sql
â”‚   â”‚   â”œâ”€â”€ fact_trips.sql
â”‚   â”‚   â””â”€â”€ fact_stop_times.sql
â”‚   â””â”€â”€ gold/             # 3 analytics tables
â”‚       â”œâ”€â”€ fct_daily_performance.sql
â”‚       â”œâ”€â”€ fct_route_analytics.sql
â”‚       â””â”€â”€ obt_positions_wide.sql
â”œâ”€â”€ macros/
â”‚   â””â”€â”€ custom_schema.sql
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ packages.yml
â””â”€â”€ README.md
```

## Key Engineering Decisions

- **Typed Bronze tables** â€” Columns cast at ingestion (not all-string), reducing Silver complexity
- **Protobuf parsing** â€” Vehicle positions decoded from binary GTFS-RT format in PySpark
- **Weather Ã— Positions join** â€” Matched on `date + hour` for hourly weather context in Gold
- **Deduplication** â€” `ROW_NUMBER()` window function in `fact_vehicle_positions` handles duplicate readings
- **GTFS time handling** â€” Stop times kept as STRING (values can exceed `24:00:00` for overnight trips)
- **Custom schema macro** â€” Prevents dbt's default `{prefix}_{schema}` concatenation in Unity Catalog

## Data Engineering Principles Applied

Based on *Fundamentals of Data Engineering* (Reis & Housley):

- **Medallion Architecture** â€” Bronze (raw) â†’ Silver (cleaned) â†’ Gold (business-ready)
- **Idempotency** â€” Re-running any pipeline produces the same result
- **Data Quality** â€” 57 automated tests, schema enforcement, NOT NULL constraints
- **Orchestration** â€” Dependency-aware scheduling with failure handling
- **Incremental Processing** â€” Watermark-based ingestion for vehicle positions
- **FinOps** â€” Serverless SQL warehouse, OPTIMIZE for storage efficiency

## Getting Started

### Prerequisites
- Databricks workspace with Unity Catalog
- Python 3.11+
- dbt-core + dbt-databricks

### Setup
```bash
# Clone the repo
git clone https://github.com/DataWithTariq/stm-dbt.git
cd stm-dbt

# Install dbt
pip install dbt-core dbt-databricks

# Install packages
dbt deps

# Configure connection (edit ~/.dbt/profiles.yml)
# Run models
dbt build  # run + test
```

## Author

**Tariq** â€” Data Engineer specializing in lakehouse architectures on Databricks and Microsoft Fabric.

[LinkedIn](https://linkedin.com/in/YOUR_LINKEDIN) Â· [GitHub](https://github.com/DataWithTariq)
